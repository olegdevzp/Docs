# Comprehensive Docker Guide for Junior Frontend & Backend Developers

## Table of Contents
1. [Introduction to Docker](#introduction-to-docker)
2. [Why Docker Matters](#why-docker-matters)
3. [Core Docker Concepts](#core-docker-concepts)
4. [Installation and Setup](#installation-and-setup)
5. [Docker Basic Commands](#docker-basic-commands)
6. [Understanding Dockerfile](#understanding-dockerfile)
7. [Docker Compose](#docker-compose)
8. [Frontend Development with Docker](#frontend-development-with-docker)
9. [Backend Development with Docker](#backend-development-with-docker)
10. [Docker Volumes and Data Persistence](#docker-volumes-and-data-persistence)
11. [Docker Networks](#docker-networks)
12. [Best Practices](#best-practices)
13. [Common Issues and Troubleshooting](#common-issues-and-troubleshooting)
14. [Docker Interview Questions](#docker-interview-questions)

---

## Introduction to Docker

### What is Docker?

Docker is an open-source platform that automates the deployment, scaling, and management of applications using **containerization**. It packages an application and its dependencies into a standardized unit called a **container** that can run consistently across different environments.

### The Problem Docker Solves

**"It works on my machine!"** - Every developer has heard or said this phrase. Docker solves this by ensuring that your application runs the same way on:
- Your local development machine
- Your colleague's computer
- Testing/staging environments
- Production servers

### Key Terms

| Term | Definition |
|------|------------|
| **Image** | A read-only template with instructions for creating a container. Think of it as a snapshot or blueprint. |
| **Container** | A runnable instance of an image. It's an isolated process with its own filesystem, networking, and resources. |
| **Dockerfile** | A text file containing instructions to build a Docker image. |
| **Registry** | A storage and distribution system for Docker images (e.g., Docker Hub). |
| **Volume** | A mechanism for persisting data generated by containers. |
| **Docker Compose** | A tool for defining and running multi-container applications. |

---

## Why Docker Matters

### For Frontend Developers

1. **Consistent Development Environment**: Ensure all team members use the same Node.js version, dependencies, and build tools.
2. **Easy Onboarding**: New developers can start coding in minutes, not days.
3. **Production Parity**: Develop and test in an environment that mirrors production.
4. **Microservices Integration**: Easily run backend APIs, databases, and other services locally.
5. **CI/CD Pipeline**: Streamline build, test, and deployment processes.

### For Backend Developers

1. **Database Management**: Run multiple databases (PostgreSQL, MongoDB, Redis) without installation conflicts.
2. **Microservices Architecture**: Develop, test, and deploy independent services.
3. **Environment Variables**: Manage configuration across different environments.
4. **Service Dependencies**: Easily mock external services or APIs.
5. **Scalability**: Learn containerization patterns used in production systems.

### Real-World Benefits

```
Without Docker:
- Install Node.js 18
- Install PostgreSQL 15
- Configure environment variables
- Install Redis
- Set up development database
- Configure ports to avoid conflicts
= 2-4 hours of setup time

With Docker:
- docker-compose up
= 2 minutes
```

---

## Core Docker Concepts

### 1. Images vs Containers

**Analogy**: Think of a Docker image as a **recipe** and a container as the **meal** prepared from that recipe.

```
Image (Recipe)          →    Container (Meal)
---------------------------------------------
node:18-alpine         →    Running Node.js app
postgres:15            →    Running database
nginx:latest           →    Running web server
```

**Key Points**:
- Images are **immutable** (read-only)
- Containers are **mutable** (can be started, stopped, deleted)
- Multiple containers can be created from one image
- Images are layered (built incrementally)

### 2. Container Lifecycle

```
                    ┌──────────┐
                    │  Created │
                    └─────┬────┘
                          │
                    ┌─────▼────┐
              ┌────►│ Running  │◄────┐
              │     └─────┬────┘     │
              │           │          │
         restart      ┌───▼───┐   start
              │       │ Paused │     │
              │       └───┬───┘     │
              │           │         │
              │      ┌────▼────┐    │
              └──────┤ Stopped ├────┘
                     └────┬────┘
                          │
                     ┌────▼────┐
                     │ Removed │
                     └─────────┘
```

### 3. Docker Architecture

```
┌─────────────────────────────────────────┐
│           Docker Client (CLI)           │
│         (docker run, docker build)      │
└──────────────────┬──────────────────────┘
                   │ REST API
┌──────────────────▼──────────────────────┐
│          Docker Daemon (dockerd)        │
│    - Manages images, containers,        │
│      networks, and volumes              │
└──────────────────┬──────────────────────┘
                   │
    ┌──────────────┼──────────────┐
    │              │              │
┌───▼───┐    ┌─────▼─────┐  ┌────▼────┐
│Images │    │Containers │  │Volumes  │
└───────┘    └───────────┘  └─────────┘
```

---

## Installation and Setup

### macOS

```bash
# Install using Homebrew
brew install --cask docker

# Or download from Docker website
# https://docs.docker.com/desktop/install/mac-install/

# Verify installation
docker --version
docker-compose --version
```

### Windows

```powershell
# Download Docker Desktop for Windows
# https://docs.docker.com/desktop/install/windows-install/

# Enable WSL 2 (Windows Subsystem for Linux)
wsl --install

# Verify installation
docker --version
docker-compose --version
```

### Linux (Ubuntu/Debian)

```bash
# Update package index
sudo apt-get update

# Install dependencies
sudo apt-get install \
    ca-certificates \
    curl \
    gnupg \
    lsb-release

# Add Docker's official GPG key
sudo mkdir -p /etc/apt/keyrings
curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo gpg --dearmor -o /etc/apt/keyrings/docker.gpg

# Set up repository
echo \
  "deb [arch=$(dpkg --print-architecture) signed-by=/etc/apt/keyrings/docker.gpg] https://download.docker.com/linux/ubuntu \
  $(lsb_release -cs) stable" | sudo tee /etc/apt/sources.list.d/docker.list > /dev/null

# Install Docker Engine
sudo apt-get update
sudo apt-get install docker-ce docker-ce-cli containerd.io docker-compose-plugin

# Verify installation
docker --version
docker compose version
```

### Post-Installation Setup (Linux)

```bash
# Run Docker without sudo
sudo groupadd docker
sudo usermod -aG docker $USER
newgrp docker

# Test Docker
docker run hello-world
```

### Verify Installation

```bash
# Check Docker version
docker --version
# Output: Docker version 24.0.0, build abc1234

# Check Docker Compose version
docker-compose --version
# Output: Docker Compose version v2.20.0

# Run hello-world container
docker run hello-world

# Check Docker info
docker info
```

---

## Docker Basic Commands

### Image Commands

```bash
# List all images
docker images
docker image ls

# Pull an image from Docker Hub
docker pull node:18-alpine
docker pull nginx:latest
docker pull postgres:15

# Build an image from Dockerfile
docker build -t my-app:1.0 .
docker build -t my-app:latest --no-cache .

# Remove an image
docker rmi image-name
docker rmi image-id

# Remove all unused images
docker image prune
docker image prune -a  # Remove all unused images, not just dangling ones

# View image history (layers)
docker history image-name

# Tag an image
docker tag my-app:1.0 my-app:latest

# Search for images on Docker Hub
docker search node
docker search postgres
```

### Container Commands

```bash
# Run a container
docker run nginx
docker run -d nginx                    # Run in detached mode (background)
docker run -d -p 8080:80 nginx        # Map port 8080 (host) to 80 (container)
docker run -d --name my-nginx nginx   # Assign a name
docker run -it ubuntu bash            # Interactive mode with terminal

# List containers
docker ps                  # Running containers only
docker ps -a              # All containers (including stopped)
docker ps -q              # Only container IDs

# Stop a container
docker stop container-name
docker stop container-id

# Start a stopped container
docker start container-name

# Restart a container
docker restart container-name

# Remove a container
docker rm container-name
docker rm -f container-name  # Force remove running container

# Remove all stopped containers
docker container prune

# View container logs
docker logs container-name
docker logs -f container-name         # Follow logs (real-time)
docker logs --tail 100 container-name # Last 100 lines

# Execute command in running container
docker exec -it container-name bash
docker exec -it container-name sh
docker exec container-name ls -la

# View container stats
docker stats
docker stats container-name

# Inspect container details
docker inspect container-name

# Copy files to/from container
docker cp file.txt container-name:/path/
docker cp container-name:/path/file.txt ./

# View container processes
docker top container-name

# Pause/unpause container
docker pause container-name
docker unpause container-name
```

### System Commands

```bash
# View Docker system information
docker info

# View Docker disk usage
docker system df

# Clean up unused resources
docker system prune              # Remove stopped containers, unused networks, dangling images
docker system prune -a           # Remove all unused images too
docker system prune --volumes    # Remove unused volumes too

# View Docker events
docker events

# View Docker version
docker version
```

### Quick Reference Cheat Sheet

```bash
# Lifecycle
docker create      # Create a container without starting it
docker run         # Create and start a container
docker start       # Start a stopped container
docker stop        # Stop a running container
docker restart     # Restart a container
docker pause       # Pause a running container
docker unpause     # Unpause a paused container
docker rm          # Remove a container
docker kill        # Kill a running container

# Information
docker ps          # List running containers
docker logs        # Show container logs
docker inspect     # Show container details
docker events      # Show real-time events
docker port        # Show container port mappings
docker top         # Show running processes in container
docker stats       # Show container resource usage

# Import/Export
docker cp          # Copy files between container and host
docker export      # Export container filesystem as tar
docker import      # Import container from tar

# Execution
docker exec        # Run command in running container
docker attach      # Attach to running container
```

---

## Understanding Dockerfile

### What is a Dockerfile?

A Dockerfile is a text document containing commands to assemble a Docker image. Think of it as a recipe with step-by-step instructions.

### Dockerfile Structure

```dockerfile
# 1. Base Image
FROM node:18-alpine

# 2. Metadata
LABEL maintainer="developer@example.com"
LABEL version="1.0"

# 3. Working Directory
WORKDIR /app

# 4. Copy Files
COPY package*.json ./

# 5. Install Dependencies
RUN npm install

# 6. Copy Application Code
COPY . .

# 7. Expose Port
EXPOSE 3000

# 8. Define Startup Command
CMD ["npm", "start"]
```

### Common Dockerfile Instructions

#### FROM - Base Image

```dockerfile
# Use official Node.js image
FROM node:18-alpine

# Use official Python image
FROM python:3.11-slim

# Use official nginx image
FROM nginx:alpine

# Multi-stage build (advanced)
FROM node:18 AS builder
```

**Best Practices**:
- Use specific versions (not `latest`)
- Prefer alpine variants for smaller images
- Use official images from Docker Hub

#### WORKDIR - Set Working Directory

```dockerfile
# Set working directory
WORKDIR /app

# All subsequent commands run from /app
COPY package.json .
RUN npm install
```

**Why Use WORKDIR?**:
- Organizes files in a consistent location
- Simplifies subsequent commands
- Easier to debug

#### COPY vs ADD

```dockerfile
# COPY - Simple file/directory copy (preferred)
COPY package.json ./
COPY src/ ./src/
COPY . .

# ADD - Advanced features (auto-extraction, URLs)
ADD archive.tar.gz /app/
ADD https://example.com/file.txt /app/
```

**Best Practice**: Use `COPY` unless you need `ADD`'s special features.

#### RUN - Execute Commands

```dockerfile
# Install dependencies
RUN npm install

# Run multiple commands
RUN apt-get update && apt-get install -y \
    curl \
    vim \
    && rm -rf /var/lib/apt/lists/*

# Chain commands to reduce layers
RUN npm install && npm run build && npm prune --production
```

**Best Practices**:
- Combine related commands with `&&`
- Clean up in the same layer
- Use `\` for multi-line commands

#### ENV - Environment Variables

```dockerfile
# Set environment variables
ENV NODE_ENV=production
ENV PORT=3000
ENV DATABASE_URL=postgresql://localhost:5432/mydb

# Use environment variables
ENV APP_HOME=/app
WORKDIR $APP_HOME
```

#### EXPOSE - Document Ports

```dockerfile
# Document that the app uses port 3000
EXPOSE 3000

# Multiple ports
EXPOSE 3000 8080
```

**Note**: `EXPOSE` is documentation only. Use `-p` flag when running container to actually map ports.

#### CMD vs ENTRYPOINT

```dockerfile
# CMD - Default command (can be overridden)
CMD ["npm", "start"]
CMD ["node", "server.js"]
CMD ["python", "app.py"]

# ENTRYPOINT - Main executable (harder to override)
ENTRYPOINT ["node"]
CMD ["server.js"]  # Default argument to ENTRYPOINT

# ENTRYPOINT + CMD combination
ENTRYPOINT ["npm"]
CMD ["start"]      # Can override with: docker run image test
```

**When to Use What**:
- Use `CMD` for default commands that might be overridden
- Use `ENTRYPOINT` for the main executable
- Use both for flexibility with default arguments

#### ARG - Build Arguments

```dockerfile
# Define build-time variables
ARG NODE_VERSION=18
FROM node:${NODE_VERSION}-alpine

ARG APP_ENV=development
ENV NODE_ENV=${APP_ENV}

# Usage during build:
# docker build --build-arg NODE_VERSION=20 --build-arg APP_ENV=production .
```

#### VOLUME - Define Mount Points

```dockerfile
# Create mount points for persistent data
VOLUME /app/data
VOLUME ["/app/logs", "/app/uploads"]
```

#### USER - Set User Context

```dockerfile
# Create non-root user (security best practice)
RUN addgroup -g 1001 appgroup && \
    adduser -D -u 1001 -G appgroup appuser

# Switch to non-root user
USER appuser

# All subsequent commands run as appuser
CMD ["npm", "start"]
```

### Complete Frontend Example (Angular)

```dockerfile
# === Build Stage ===
FROM node:18-alpine AS builder

# Set working directory
WORKDIR /app

# Copy package files
COPY package*.json ./

# Install dependencies
RUN npm ci

# Copy source code
COPY . .

# Build application
RUN npm run build -- --configuration=production

# === Production Stage ===
FROM nginx:alpine

# Copy custom nginx config
COPY nginx.conf /etc/nginx/nginx.conf

# Copy built application from builder stage
COPY --from=builder /app/dist/my-angular-app /usr/share/nginx/html

# Expose port 80
EXPOSE 80

# Start nginx
CMD ["nginx", "-g", "daemon off;"]
```

### Complete Backend Example (Node.js/Express)

```dockerfile
# Use official Node.js LTS image
FROM node:18-alpine

# Set working directory
WORKDIR /app

# Copy package files
COPY package*.json ./

# Install production dependencies only
RUN npm ci --only=production

# Copy application code
COPY . .

# Create non-root user
RUN addgroup -g 1001 nodejs && \
    adduser -D -u 1001 -G nodejs nodejs

# Change ownership of app directory
RUN chown -R nodejs:nodejs /app

# Switch to non-root user
USER nodejs

# Expose port
EXPOSE 3000

# Health check
HEALTHCHECK --interval=30s --timeout=3s --start-period=5s --retries=3 \
  CMD node healthcheck.js || exit 1

# Start application
CMD ["node", "server.js"]
```

### Multi-Stage Build Example (React + Node.js)

```dockerfile
# === Build Frontend ===
FROM node:18-alpine AS frontend-builder

WORKDIR /app/frontend

COPY frontend/package*.json ./
RUN npm ci

COPY frontend/ ./
RUN npm run build

# === Build Backend ===
FROM node:18-alpine AS backend-builder

WORKDIR /app/backend

COPY backend/package*.json ./
RUN npm ci --only=production

COPY backend/ ./

# === Final Stage ===
FROM node:18-alpine

WORKDIR /app

# Copy backend
COPY --from=backend-builder /app/backend ./

# Copy frontend build
COPY --from=frontend-builder /app/frontend/build ./public

# Create non-root user
RUN addgroup -g 1001 appgroup && \
    adduser -D -u 1001 -G appgroup appuser && \
    chown -R appuser:appgroup /app

USER appuser

EXPOSE 3000

CMD ["node", "server.js"]
```

### Dockerfile Best Practices

1. **Use .dockerignore**

```dockerignore
node_modules
npm-debug.log
.git
.gitignore
.env
.env.local
dist
build
coverage
.vscode
.idea
*.md
Dockerfile
docker-compose.yml
```

2. **Order Instructions by Change Frequency**

```dockerfile
# Less frequently changed (bottom layers)
FROM node:18-alpine
WORKDIR /app
COPY package*.json ./
RUN npm install

# More frequently changed (top layers)
COPY . .
CMD ["npm", "start"]
```

3. **Minimize Layers**

```dockerfile
# Bad - Multiple layers
RUN apt-get update
RUN apt-get install -y curl
RUN apt-get install -y vim
RUN rm -rf /var/lib/apt/lists/*

# Good - Single layer
RUN apt-get update && \
    apt-get install -y curl vim && \
    rm -rf /var/lib/apt/lists/*
```

4. **Use Alpine Images**

```dockerfile
# 900MB+
FROM node:18

# 175MB
FROM node:18-alpine
```

5. **Don't Run as Root**

```dockerfile
# Create and use non-root user
RUN adduser -D appuser
USER appuser
```

---

## Docker Compose

### What is Docker Compose?

Docker Compose is a tool for defining and running multi-container Docker applications. With Compose, you use a YAML file to configure your application's services, networks, and volumes.

### Why Use Docker Compose?

```bash
# Without Docker Compose (manual)
docker network create my-network
docker run -d --name postgres --network my-network -e POSTGRES_PASSWORD=secret postgres:15
docker run -d --name redis --network my-network redis:alpine
docker run -d --name backend --network my-network -p 3000:3000 my-backend-app
docker run -d --name frontend --network my-network -p 4200:4200 my-frontend-app

# With Docker Compose (automated)
docker-compose up
```

### Basic docker-compose.yml Structure

```yaml
version: '3.8'

services:
  # Service definitions
  service-name:
    image: image-name
    ports:
      - "host:container"
    environment:
      - KEY=value

volumes:
  # Volume definitions

networks:
  # Network definitions
```

### Frontend Development Example (Angular + Node.js API)

```yaml
version: '3.8'

services:
  # Frontend - Angular Application
  frontend:
    build:
      context: ./frontend
      dockerfile: Dockerfile.dev
    container_name: angular-frontend
    ports:
      - "4200:4200"
    volumes:
      - ./frontend:/app
      - /app/node_modules  # Anonymous volume to prevent overwriting
    environment:
      - NODE_ENV=development
      - API_URL=http://backend:3000
    command: npm start
    depends_on:
      - backend
    networks:
      - app-network

  # Backend - Node.js API
  backend:
    build:
      context: ./backend
      dockerfile: Dockerfile.dev
    container_name: node-backend
    ports:
      - "3000:3000"
    volumes:
      - ./backend:/app
      - /app/node_modules
    environment:
      - NODE_ENV=development
      - DATABASE_URL=postgresql://postgres:password@database:5432/myapp
      - REDIS_URL=redis://redis:6379
      - JWT_SECRET=your-secret-key
    depends_on:
      - database
      - redis
    networks:
      - app-network

  # Database - PostgreSQL
  database:
    image: postgres:15-alpine
    container_name: postgres-db
    ports:
      - "5432:5432"
    environment:
      - POSTGRES_USER=postgres
      - POSTGRES_PASSWORD=password
      - POSTGRES_DB=myapp
    volumes:
      - postgres-data:/var/lib/postgresql/data
      - ./database/init.sql:/docker-entrypoint-initdb.d/init.sql
    networks:
      - app-network

  # Cache - Redis
  redis:
    image: redis:7-alpine
    container_name: redis-cache
    ports:
      - "6379:6379"
    volumes:
      - redis-data:/data
    command: redis-server --appendonly yes
    networks:
      - app-network

volumes:
  postgres-data:
  redis-data:

networks:
  app-network:
    driver: bridge
```

### Full-Stack Example with Multiple Services

```yaml
version: '3.8'

services:
  # Nginx Reverse Proxy
  nginx:
    image: nginx:alpine
    container_name: nginx-proxy
    ports:
      - "80:80"
      - "443:443"
    volumes:
      - ./nginx/nginx.conf:/etc/nginx/nginx.conf:ro
      - ./nginx/ssl:/etc/nginx/ssl:ro
    depends_on:
      - frontend
      - backend
    networks:
      - app-network

  # Frontend Application
  frontend:
    build:
      context: ./frontend
      dockerfile: Dockerfile
      args:
        - NODE_ENV=production
    container_name: react-frontend
    environment:
      - REACT_APP_API_URL=http://localhost/api
    networks:
      - app-network

  # Backend API
  backend:
    build:
      context: ./backend
      dockerfile: Dockerfile
    container_name: express-backend
    environment:
      - NODE_ENV=production
      - DATABASE_URL=postgresql://postgres:password@postgres:5432/myapp
      - REDIS_URL=redis://redis:6379
      - MONGODB_URL=mongodb://mongo:27017/myapp
    depends_on:
      - postgres
      - mongo
      - redis
    networks:
      - app-network
    restart: unless-stopped

  # PostgreSQL Database
  postgres:
    image: postgres:15-alpine
    container_name: postgres-db
    environment:
      - POSTGRES_USER=postgres
      - POSTGRES_PASSWORD=password
      - POSTGRES_DB=myapp
    volumes:
      - postgres-data:/var/lib/postgresql/data
    networks:
      - app-network
    restart: unless-stopped

  # MongoDB Database
  mongo:
    image: mongo:7
    container_name: mongodb
    environment:
      - MONGO_INITDB_ROOT_USERNAME=admin
      - MONGO_INITDB_ROOT_PASSWORD=password
    volumes:
      - mongo-data:/data/db
    networks:
      - app-network
    restart: unless-stopped

  # Redis Cache
  redis:
    image: redis:7-alpine
    container_name: redis-cache
    command: redis-server --requirepass password
    volumes:
      - redis-data:/data
    networks:
      - app-network
    restart: unless-stopped

  # Adminer (Database Management)
  adminer:
    image: adminer:latest
    container_name: adminer
    ports:
      - "8080:8080"
    depends_on:
      - postgres
      - mongo
    networks:
      - app-network

volumes:
  postgres-data:
  mongo-data:
  redis-data:

networks:
  app-network:
    driver: bridge
```

### Docker Compose Commands

```bash
# Start services
docker-compose up
docker-compose up -d              # Detached mode
docker-compose up --build         # Rebuild images
docker-compose up service-name    # Start specific service

# Stop services
docker-compose down               # Stop and remove containers
docker-compose down -v            # Also remove volumes
docker-compose stop               # Stop without removing
docker-compose stop service-name  # Stop specific service

# View logs
docker-compose logs
docker-compose logs -f            # Follow logs
docker-compose logs service-name  # Logs for specific service
docker-compose logs --tail=100    # Last 100 lines

# List services
docker-compose ps
docker-compose ps -a

# Execute commands
docker-compose exec service-name bash
docker-compose exec backend npm test
docker-compose exec database psql -U postgres

# Build images
docker-compose build
docker-compose build --no-cache
docker-compose build service-name

# Scale services
docker-compose up -d --scale backend=3

# View configuration
docker-compose config
docker-compose config --services

# Restart services
docker-compose restart
docker-compose restart service-name

# Pause/Unpause services
docker-compose pause
docker-compose unpause

# Remove stopped containers
docker-compose rm
docker-compose rm -f

# Pull images
docker-compose pull

# View running processes
docker-compose top
```

### Environment Variables in Docker Compose

#### Using .env File

```bash
# .env file
NODE_ENV=development
DATABASE_HOST=postgres
DATABASE_PORT=5432
DATABASE_NAME=myapp
DATABASE_USER=postgres
DATABASE_PASSWORD=secret123
REDIS_HOST=redis
REDIS_PORT=6379
API_PORT=3000
FRONTEND_PORT=4200
```

```yaml
# docker-compose.yml
version: '3.8'

services:
  backend:
    image: node:18-alpine
    ports:
      - "${API_PORT}:3000"
    environment:
      - NODE_ENV=${NODE_ENV}
      - DATABASE_URL=postgresql://${DATABASE_USER}:${DATABASE_PASSWORD}@${DATABASE_HOST}:${DATABASE_PORT}/${DATABASE_NAME}
      - REDIS_URL=redis://${REDIS_HOST}:${REDIS_PORT}

  database:
    image: postgres:15-alpine
    environment:
      - POSTGRES_USER=${DATABASE_USER}
      - POSTGRES_PASSWORD=${DATABASE_PASSWORD}
      - POSTGRES_DB=${DATABASE_NAME}
```

#### Using Multiple Env Files

```bash
# docker-compose.override.yml for development
version: '3.8'

services:
  backend:
    env_file:
      - .env.development
    volumes:
      - ./backend:/app
    command: npm run dev

# docker-compose.prod.yml for production
version: '3.8'

services:
  backend:
    env_file:
      - .env.production
    command: npm start
```

```bash
# Run with specific file
docker-compose -f docker-compose.yml -f docker-compose.prod.yml up
```

### Advanced Docker Compose Features

#### Health Checks

```yaml
services:
  backend:
    image: my-backend
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:3000/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s

  database:
    image: postgres:15-alpine
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U postgres"]
      interval: 10s
      timeout: 5s
      retries: 5
```

#### Depends On with Conditions

```yaml
services:
  backend:
    depends_on:
      database:
        condition: service_healthy
      redis:
        condition: service_started

  database:
    healthcheck:
      test: ["CMD-SHELL", "pg_isready"]
      interval: 10s
      timeout: 5s
      retries: 5
```

#### Resource Limits

```yaml
services:
  backend:
    image: my-backend
    deploy:
      resources:
        limits:
          cpus: '0.50'
          memory: 512M
        reservations:
          cpus: '0.25'
          memory: 256M
```

#### Restart Policies

```yaml
services:
  backend:
    image: my-backend
    restart: always        # Always restart
    # restart: unless-stopped  # Restart unless manually stopped
    # restart: on-failure     # Restart only on failure
    # restart: no             # Never restart
```

---

## Frontend Development with Docker

### Angular Development Setup

#### Dockerfile.dev (Development)

```dockerfile
FROM node:18-alpine

WORKDIR /app

# Install Angular CLI globally
RUN npm install -g @angular/cli@16

# Copy package files
COPY package*.json ./

# Install dependencies
RUN npm install

# Copy application code
COPY . .

# Expose port
EXPOSE 4200

# Start development server
CMD ["ng", "serve", "--host", "0.0.0.0", "--poll", "2000"]
```

#### Dockerfile (Production)

```dockerfile
# === Build Stage ===
FROM node:18-alpine AS build

WORKDIR /app

COPY package*.json ./
RUN npm ci

COPY . .
RUN npm run build -- --configuration=production

# === Production Stage ===
FROM nginx:alpine

# Copy custom nginx configuration
COPY nginx.conf /etc/nginx/nginx.conf

# Copy built application
COPY --from=build /app/dist/my-app /usr/share/nginx/html

# Expose port
EXPOSE 80

# Start nginx
CMD ["nginx", "-g", "daemon off;"]
```

#### nginx.conf for Angular

```nginx
events {
    worker_connections 1024;
}

http {
    include /etc/nginx/mime.types;
    default_type application/octet-stream;

    sendfile on;
    keepalive_timeout 65;
    gzip on;

    server {
        listen 80;
        server_name localhost;
        root /usr/share/nginx/html;
        index index.html;

        # Enable gzip compression
        gzip_types text/plain text/css application/json application/javascript text/xml application/xml application/xml+rss text/javascript;

        # Angular routing - serve index.html for all routes
        location / {
            try_files $uri $uri/ /index.html;
        }

        # Cache static assets
        location ~* \.(jpg|jpeg|png|gif|ico|css|js|svg|woff|woff2|ttf|eot)$ {
            expires 1y;
            add_header Cache-Control "public, immutable";
        }

        # Security headers
        add_header X-Frame-Options "SAMEORIGIN" always;
        add_header X-Content-Type-Options "nosniff" always;
        add_header X-XSS-Protection "1; mode=block" always;
    }
}
```

#### docker-compose.yml for Angular

```yaml
version: '3.8'

services:
  angular-app:
    build:
      context: .
      dockerfile: Dockerfile.dev
    container_name: angular-dev
    ports:
      - "4200:4200"
    volumes:
      - .:/app
      - /app/node_modules
    environment:
      - CHOKIDAR_USEPOLLING=true
      - NODE_ENV=development
    networks:
      - frontend-network

  api-mock:
    image: mockserver/mockserver:latest
    ports:
      - "1080:1080"
    environment:
      - MOCKSERVER_INITIALIZATION_JSON_PATH=/config/mock-config.json
    volumes:
      - ./mock-server:/config
    networks:
      - frontend-network

networks:
  frontend-network:
    driver: bridge
```

### React Development Setup

#### Dockerfile.dev

```dockerfile
FROM node:18-alpine

WORKDIR /app

# Copy package files
COPY package*.json ./

# Install dependencies
RUN npm install

# Copy application code
COPY . .

# Expose port
EXPOSE 3000

# Start development server
CMD ["npm", "start"]
```

#### Dockerfile (Production with Multi-Stage)

```dockerfile
# === Build Stage ===
FROM node:18-alpine AS build

WORKDIR /app

COPY package*.json ./
RUN npm ci

COPY . .
RUN npm run build

# === Production Stage ===
FROM nginx:alpine

COPY --from=build /app/build /usr/share/nginx/html
COPY nginx.conf /etc/nginx/conf.d/default.conf

EXPOSE 80

CMD ["nginx", "-g", "daemon off;"]
```

#### docker-compose.yml for React

```yaml
version: '3.8'

services:
  react-app:
    build:
      context: .
      dockerfile: Dockerfile.dev
    container_name: react-dev
    ports:
      - "3000:3000"
    volumes:
      - .:/app
      - /app/node_modules
    environment:
      - CHOKIDAR_USEPOLLING=true
      - REACT_APP_API_URL=http://localhost:4000/api
      - WATCHPACK_POLLING=true
    stdin_open: true
    tty: true
    networks:
      - app-network

networks:
  app-network:
    driver: bridge
```

### Vue.js Development Setup

#### Dockerfile.dev

```dockerfile
FROM node:18-alpine

WORKDIR /app

COPY package*.json ./
RUN npm install

COPY . .

EXPOSE 8080

CMD ["npm", "run", "serve"]
```

#### docker-compose.yml for Vue

```yaml
version: '3.8'

services:
  vue-app:
    build:
      context: .
      dockerfile: Dockerfile.dev
    container_name: vue-dev
    ports:
      - "8080:8080"
    volumes:
      - .:/app
      - /app/node_modules
    environment:
      - VUE_APP_API_URL=http://localhost:4000
      - CHOKIDAR_USEPOLLING=true
    networks:
      - app-network

networks:
  app-network:
    driver: bridge
```

### Common Frontend Dockerfile Issues and Solutions

#### Issue 1: Hot Reload Not Working

**Solution**: Enable polling in Docker

```yaml
# docker-compose.yml
services:
  frontend:
    environment:
      - CHOKIDAR_USEPOLLING=true
      - WATCHPACK_POLLING=true
    volumes:
      - .:/app
      - /app/node_modules  # Prevent overwriting node_modules
```

```json
// package.json - Angular
{
  "scripts": {
    "start": "ng serve --host 0.0.0.0 --poll 2000"
  }
}
```

```json
// package.json - React
{
  "scripts": {
    "start": "WATCHPACK_POLLING=true react-scripts start"
  }
}
```

#### Issue 2: Permission Denied on node_modules

**Solution**: Use anonymous volume

```yaml
volumes:
  - .:/app
  - /app/node_modules  # Anonymous volume overrides bind mount
```

#### Issue 3: Large Image Size

**Solution**: Use multi-stage builds and alpine images

```dockerfile
# Build stage
FROM node:18-alpine AS build
WORKDIR /app
COPY package*.json ./
RUN npm ci
COPY . .
RUN npm run build

# Production stage - much smaller
FROM nginx:alpine
COPY --from=build /app/dist /usr/share/nginx/html
```

---

## Backend Development with Docker

### Node.js/Express Setup

#### Dockerfile.dev (Development with Nodemon)

```dockerfile
FROM node:18-alpine

WORKDIR /app

# Install nodemon globally for development
RUN npm install -g nodemon

# Copy package files
COPY package*.json ./

# Install dependencies
RUN npm install

# Copy application code
COPY . .

# Expose port
EXPOSE 3000

# Start with nodemon for auto-reload
CMD ["nodemon", "server.js"]
```

#### Dockerfile (Production)

```dockerfile
FROM node:18-alpine

# Create app directory
WORKDIR /app

# Copy package files
COPY package*.json ./

# Install production dependencies only
RUN npm ci --only=production

# Copy application code
COPY . .

# Create non-root user
RUN addgroup -g 1001 nodejs && \
    adduser -D -u 1001 -G nodejs nodejs && \
    chown -R nodejs:nodejs /app

# Switch to non-root user
USER nodejs

# Expose port
EXPOSE 3000

# Health check
HEALTHCHECK --interval=30s --timeout=3s --start-period=10s --retries=3 \
  CMD node healthcheck.js || exit 1

# Start application
CMD ["node", "server.js"]
```

#### docker-compose.yml for Node.js API

```yaml
version: '3.8'

services:
  # Node.js API
  api:
    build:
      context: .
      dockerfile: Dockerfile.dev
    container_name: node-api
    ports:
      - "3000:3000"
    volumes:
      - .:/app
      - /app/node_modules
    environment:
      - NODE_ENV=development
      - PORT=3000
      - DATABASE_URL=postgresql://postgres:password@postgres:5432/mydb
      - REDIS_URL=redis://redis:6379
      - JWT_SECRET=dev-secret-key
      - LOG_LEVEL=debug
    depends_on:
      - postgres
      - redis
    networks:
      - backend-network
    command: nodemon --inspect=0.0.0.0:9229 server.js  # Enable debugging

  # PostgreSQL Database
  postgres:
    image: postgres:15-alpine
    container_name: postgres-db
    ports:
      - "5432:5432"
    environment:
      - POSTGRES_USER=postgres
      - POSTGRES_PASSWORD=password
      - POSTGRES_DB=mydb
    volumes:
      - postgres-data:/var/lib/postgresql/data
      - ./database/init.sql:/docker-entrypoint-initdb.d/init.sql
    networks:
      - backend-network
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U postgres"]
      interval: 10s
      timeout: 5s
      retries: 5

  # Redis Cache
  redis:
    image: redis:7-alpine
    container_name: redis-cache
    ports:
      - "6379:6379"
    volumes:
      - redis-data:/data
    networks:
      - backend-network
    command: redis-server --appendonly yes
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 10s
      timeout: 3s
      retries: 5

  # pgAdmin (Database Management)
  pgadmin:
    image: dpage/pgadmin4:latest
    container_name: pgadmin
    ports:
      - "5050:80"
    environment:
      - PGADMIN_DEFAULT_EMAIL=admin@admin.com
      - PGADMIN_DEFAULT_PASSWORD=admin
    depends_on:
      - postgres
    networks:
      - backend-network

volumes:
  postgres-data:
  redis-data:

networks:
  backend-network:
    driver: bridge
```

### NestJS Setup

#### Dockerfile.dev

```dockerfile
FROM node:18-alpine

WORKDIR /app

# Install NestJS CLI
RUN npm install -g @nestjs/cli

# Copy package files
COPY package*.json ./

# Install dependencies
RUN npm install

# Copy application code
COPY . .

# Expose port
EXPOSE 3000

# Start in development mode with watch
CMD ["npm", "run", "start:dev"]
```

#### Dockerfile (Production)

```dockerfile
# === Build Stage ===
FROM node:18-alpine AS builder

WORKDIR /app

COPY package*.json ./
RUN npm ci

COPY . .
RUN npm run build

# === Production Stage ===
FROM node:18-alpine

WORKDIR /app

COPY package*.json ./
RUN npm ci --only=production

# Copy built application
COPY --from=builder /app/dist ./dist

# Create non-root user
RUN addgroup -g 1001 nodejs && \
    adduser -D -u 1001 -G nodejs nodejs && \
    chown -R nodejs:nodejs /app

USER nodejs

EXPOSE 3000

CMD ["node", "dist/main"]
```

#### docker-compose.yml for NestJS

```yaml
version: '3.8'

services:
  nestjs-app:
    build:
      context: .
      dockerfile: Dockerfile.dev
    container_name: nestjs-dev
    ports:
      - "3000:3000"
      - "9229:9229"  # Debug port
    volumes:
      - .:/app
      - /app/node_modules
      - /app/dist
    environment:
      - NODE_ENV=development
      - DATABASE_HOST=postgres
      - DATABASE_PORT=5432
      - DATABASE_USER=postgres
      - DATABASE_PASSWORD=password
      - DATABASE_NAME=nestjs_db
      - REDIS_HOST=redis
      - REDIS_PORT=6379
    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
    networks:
      - nestjs-network
    command: npm run start:debug  # Enable debugging

  postgres:
    image: postgres:15-alpine
    container_name: postgres-nestjs
    environment:
      - POSTGRES_USER=postgres
      - POSTGRES_PASSWORD=password
      - POSTGRES_DB=nestjs_db
    ports:
      - "5432:5432"
    volumes:
      - postgres-data:/var/lib/postgresql/data
    networks:
      - nestjs-network
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U postgres"]
      interval: 10s
      timeout: 5s
      retries: 5

  redis:
    image: redis:7-alpine
    container_name: redis-nestjs
    ports:
      - "6379:6379"
    volumes:
      - redis-data:/data
    networks:
      - nestjs-network
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 10s
      timeout: 3s
      retries: 5

volumes:
  postgres-data:
  redis-data:

networks:
  nestjs-network:
    driver: bridge
```

### Python/Flask Setup

#### Dockerfile

```dockerfile
FROM python:3.11-slim

WORKDIR /app

# Install system dependencies
RUN apt-get update && apt-get install -y \
    gcc \
    postgresql-client \
    && rm -rf /var/lib/apt/lists/*

# Copy requirements
COPY requirements.txt .

# Install Python dependencies
RUN pip install --no-cache-dir -r requirements.txt

# Copy application code
COPY . .

# Create non-root user
RUN useradd -m -u 1001 appuser && \
    chown -R appuser:appuser /app

USER appuser

EXPOSE 5000

# Run with gunicorn in production
CMD ["gunicorn", "--bind", "0.0.0.0:5000", "--workers", "4", "app:app"]
```

#### docker-compose.yml for Flask

```yaml
version: '3.8'

services:
  flask-app:
    build: .
    container_name: flask-api
    ports:
      - "5000:5000"
    volumes:
      - .:/app
    environment:
      - FLASK_APP=app.py
      - FLASK_ENV=development
      - DATABASE_URL=postgresql://postgres:password@postgres:5432/flask_db
    depends_on:
      - postgres
    networks:
      - flask-network
    command: flask run --host=0.0.0.0

  postgres:
    image: postgres:15-alpine
    environment:
      - POSTGRES_USER=postgres
      - POSTGRES_PASSWORD=password
      - POSTGRES_DB=flask_db
    volumes:
      - postgres-data:/var/lib/postgresql/data
    networks:
      - flask-network

volumes:
  postgres-data:

networks:
  flask-network:
    driver: bridge
```

### Debugging Backend Applications in Docker

#### Node.js Debugging

```yaml
# docker-compose.yml
services:
  api:
    ports:
      - "9229:9229"  # Debug port
    command: nodemon --inspect=0.0.0.0:9229 server.js
```

```json
// .vscode/launch.json
{
  "version": "0.2.0",
  "configurations": [
    {
      "name": "Docker: Attach to Node",
      "type": "node",
      "request": "attach",
      "port": 9229,
      "address": "localhost",
      "localRoot": "${workspaceFolder}",
      "remoteRoot": "/app",
      "protocol": "inspector"
    }
  ]
}
```

#### NestJS Debugging

```yaml
services:
  nestjs-app:
    ports:
      - "9229:9229"
    command: npm run start:debug
```

```json
// .vscode/launch.json
{
  "version": "0.2.0",
  "configurations": [
    {
      "name": "Docker: Attach to NestJS",
      "type": "node",
      "request": "attach",
      "port": 9229,
      "restart": true,
      "sourceMaps": true,
      "localRoot": "${workspaceFolder}",
      "remoteRoot": "/app",
      "outFiles": ["${workspaceFolder}/dist/**/*.js"]
    }
  ]
}
```

---

## Docker Volumes and Data Persistence

### Understanding Volumes

Containers are **ephemeral** - when you delete a container, all data inside is lost. Volumes solve this by persisting data outside the container.

### Types of Volumes

```
┌─────────────────────────────────────────────┐
│         Docker Volume Types                 │
├─────────────────────────────────────────────┤
│                                             │
│  1. Named Volumes (Managed by Docker)       │
│     docker run -v mydata:/app/data          │
│                                             │
│  2. Bind Mounts (Map to host directory)     │
│     docker run -v /host/path:/container     │
│                                             │
│  3. Anonymous Volumes (Temporary)           │
│     docker run -v /app/node_modules         │
│                                             │
│  4. tmpfs Mounts (In-memory, Linux only)    │
│     docker run --tmpfs /app/temp            │
│                                             │
└─────────────────────────────────────────────┘
```

### Named Volumes

```bash
# Create a named volume
docker volume create mydata

# List volumes
docker volume ls

# Inspect volume
docker volume inspect mydata

# Use volume with container
docker run -v mydata:/app/data my-app

# Remove volume
docker volume rm mydata

# Remove all unused volumes
docker volume prune
```

**Example with PostgreSQL:**

```bash
# Create volume for database
docker volume create postgres-data

# Run PostgreSQL with persistent storage
docker run -d \
  --name postgres \
  -v postgres-data:/var/lib/postgresql/data \
  -e POSTGRES_PASSWORD=password \
  postgres:15-alpine
```

### Bind Mounts

```bash
# Mount current directory to /app
docker run -v $(pwd):/app my-app

# Mount with read-only access
docker run -v $(pwd):/app:ro my-app

# Multiple mounts
docker run \
  -v $(pwd)/src:/app/src \
  -v $(pwd)/public:/app/public \
  my-app
```

**Use Cases:**
- Development: Live code reloading
- Configuration: Mount config files
- Logs: Access logs on host

### Anonymous Volumes

```bash
# Create anonymous volume
docker run -v /app/node_modules my-app

# Docker generates random name
# Deleted when container is removed with -v flag
docker rm -v container-name
```

**Use Case:** Prevent bind mount from overwriting container directory

```yaml
# docker-compose.yml
services:
  app:
    volumes:
      - .:/app              # Bind mount
      - /app/node_modules   # Anonymous volume (takes precedence)
```

### Volume Examples in Docker Compose

```yaml
version: '3.8'

services:
  # Backend with multiple volume types
  backend:
    image: node:18-alpine
    volumes:
      # Bind mount for development
      - ./backend:/app
      
      # Anonymous volume to preserve node_modules
      - /app/node_modules
      
      # Named volume for logs
      - logs:/app/logs
      
      # Named volume for uploads
      - uploads:/app/uploads
      
      # Read-only config
      - ./config/app.config.json:/app/config.json:ro

  # Database with persistent storage
  postgres:
    image: postgres:15-alpine
    volumes:
      # Named volume for data persistence
      - postgres-data:/var/lib/postgresql/data
      
      # Bind mount for init scripts
      - ./database/init.sql:/docker-entrypoint-initdb.d/init.sql:ro

  # Redis with persistent storage
  redis:
    image: redis:7-alpine
    volumes:
      - redis-data:/data
    command: redis-server --appendonly yes

volumes:
  # Named volumes (managed by Docker)
  postgres-data:
    driver: local
  redis-data:
    driver: local
  logs:
    driver: local
  uploads:
    driver: local
```

### Advanced Volume Configurations

#### Volume with Driver Options

```yaml
volumes:
  postgres-data:
    driver: local
    driver_opts:
      type: none
      device: /path/to/data
      o: bind

  nfs-data:
    driver: local
    driver_opts:
      type: nfs
      o: addr=192.168.1.100,rw
      device: ":/path/to/nfs/share"
```

#### External Volumes

```yaml
# Use existing volume created outside Docker Compose
volumes:
  existing-volume:
    external: true
    name: my-pre-existing-volume
```

```bash
# Create volume separately
docker volume create my-pre-existing-volume

# Use it in Docker Compose
docker-compose up
```

### Backup and Restore Volumes

#### Backup Volume

```bash
# Backup PostgreSQL data
docker run --rm \
  -v postgres-data:/data \
  -v $(pwd):/backup \
  alpine \
  tar czf /backup/postgres-backup.tar.gz -C /data .

# Or with docker-compose
docker-compose exec -T postgres pg_dump -U postgres mydb > backup.sql
```

#### Restore Volume

```bash
# Restore from backup
docker run --rm \
  -v postgres-data:/data \
  -v $(pwd):/backup \
  alpine \
  tar xzf /backup/postgres-backup.tar.gz -C /data

# Or with docker-compose
docker-compose exec -T postgres psql -U postgres mydb < backup.sql
```

### Volume Best Practices

1. **Use Named Volumes for Databases**

```yaml
services:
  postgres:
    volumes:
      - postgres-data:/var/lib/postgresql/data  # ✅ Good

volumes:
  postgres-data:
```

2. **Use Bind Mounts for Development**

```yaml
services:
  app:
    volumes:
      - .:/app              # ✅ Good for development
      - /app/node_modules   # ✅ Prevent overwrite
```

3. **Don't Mix Data and Code Volumes**

```yaml
# ❌ Bad - Don't put database data in bind mount
volumes:
  - ./data:/var/lib/postgresql/data

# ✅ Good - Use named volume
volumes:
  - postgres-data:/var/lib/postgresql/data
```

4. **Use Read-Only When Possible**

```yaml
volumes:
  - ./config.json:/app/config.json:ro  # ✅ Read-only
```

---

## Docker Networks

### Understanding Docker Networks

Docker networks allow containers to communicate with each other and the outside world.

### Network Types

```
┌────────────────────────────────────────────┐
│       Docker Network Drivers               │
├────────────────────────────────────────────┤
│                                            │
│  1. bridge (default)                       │
│     - Containers on same host              │
│     - Isolated from host network           │
│                                            │
│  2. host                                   │
│     - Container uses host network          │
│     - No network isolation                 │
│                                            │
│  3. none                                   │
│     - No networking                        │
│     - Completely isolated                  │
│                                            │
│  4. overlay                                │
│     - Multi-host networking                │
│     - Docker Swarm                         │
│                                            │
│  5. macvlan                                │
│     - Assign MAC address to container      │
│     - Appears as physical device           │
│                                            │
└────────────────────────────────────────────┘
```

### Default Bridge Network

```bash
# List networks
docker network ls

# Inspect default bridge
docker network inspect bridge

# Run containers on default bridge
docker run -d --name app1 nginx
docker run -d --name app2 nginx

# Containers can't communicate by name (only IP)
```

### Custom Bridge Network

```bash
# Create custom network
docker network create my-network

# Run containers on custom network
docker run -d --name app1 --network my-network nginx
docker run -d --name app2 --network my-network nginx

# Containers can communicate by name
docker exec app1 ping app2  # ✅ Works!

# Remove network
docker network rm my-network
```

### Network Commands

```bash
# Create network
docker network create my-network
docker network create --driver bridge my-bridge-network

# List networks
docker network ls

# Inspect network
docker network inspect my-network

# Connect container to network
docker network connect my-network container-name

# Disconnect container from network
docker network disconnect my-network container-name

# Remove network
docker network rm my-network

# Remove all unused networks
docker network prune
```

### Networks in Docker Compose

#### Basic Network Configuration

```yaml
version: '3.8'

services:
  frontend:
    image: nginx
    networks:
      - frontend-network

  backend:
    image: node:18-alpine
    networks:
      - frontend-network
      - backend-network

  database:
    image: postgres:15-alpine
    networks:
      - backend-network

networks:
  frontend-network:
    driver: bridge
  backend-network:
    driver: bridge
```

**Network Isolation:**
```
frontend ─────┐
              │
              ├── frontend-network ── backend ── backend-network ── database
              │
(Can't reach database directly)
```

#### Advanced Network Configuration

```yaml
version: '3.8'

services:
  app:
    image: my-app
    networks:
      app-network:
        ipv4_address: 172.20.0.10

networks:
  app-network:
    driver: bridge
    ipam:
      config:
        - subnet: 172.20.0.0/16
          gateway: 172.20.0.1
```

#### External Networks

```yaml
# Use network created outside Docker Compose
networks:
  existing-network:
    external: true
    name: my-pre-existing-network
```

```bash
# Create network separately
docker network create my-pre-existing-network

# Use it in Docker Compose
docker-compose up
```

### Communication Patterns

#### Frontend → Backend → Database

```yaml
version: '3.8'

services:
  # Public-facing frontend
  frontend:
    build: ./frontend
    ports:
      - "80:80"
    networks:
      - public-network
    environment:
      - API_URL=http://backend:3000

  # Internal backend API
  backend:
    build: ./backend
    networks:
      - public-network
      - private-network
    environment:
      - DATABASE_URL=postgresql://postgres:password@database:5432/mydb

  # Private database
  database:
    image: postgres:15-alpine
    networks:
      - private-network
    environment:
      - POSTGRES_PASSWORD=password

networks:
  public-network:    # Frontend + Backend
  private-network:   # Backend + Database only
```

#### Microservices Architecture

```yaml
version: '3.8'

services:
  # API Gateway
  api-gateway:
    image: nginx
    ports:
      - "80:80"
    networks:
      - gateway-network

  # User Service
  user-service:
    build: ./services/user
    networks:
      - gateway-network
      - user-db-network

  user-db:
    image: postgres:15-alpine
    networks:
      - user-db-network

  # Order Service
  order-service:
    build: ./services/order
    networks:
      - gateway-network
      - order-db-network

  order-db:
    image: postgres:15-alpine
    networks:
      - order-db-network

  # Message Queue (shared)
  rabbitmq:
    image: rabbitmq:3-management
    networks:
      - gateway-network

networks:
  gateway-network:
  user-db-network:
  order-db-network:
```

### Network Debugging

```bash
# Inspect network
docker network inspect my-network

# Check container connectivity
docker exec container1 ping container2

# View container's network interfaces
docker exec container1 ip addr

# Test DNS resolution
docker exec container1 nslookup container2

# Check open ports
docker exec container1 netstat -tuln

# Trace route
docker exec container1 traceroute container2
```

### Network Best Practices

1. **Use Custom Networks**

```yaml
# ✅ Good - Custom network
networks:
  app-network:
    driver: bridge

# ❌ Bad - Default bridge
# (No automatic DNS resolution)
```

2. **Implement Network Segmentation**

```yaml
# ✅ Good - Separate networks for different layers
services:
  frontend:
    networks:
      - public
  
  backend:
    networks:
      - public
      - private
  
  database:
    networks:
      - private  # Not exposed to frontend

networks:
  public:
  private:
```

3. **Use Meaningful Network Names**

```yaml
# ✅ Good
networks:
  frontend-network:
  backend-network:
  database-network:

# ❌ Bad
networks:
  network1:
  network2:
```

---

## Best Practices

### 1. Security Best Practices

#### Don't Run as Root

```dockerfile
# ✅ Good - Create non-root user
FROM node:18-alpine

WORKDIR /app

COPY package*.json ./
RUN npm ci --only=production

COPY . .

# Create user
RUN addgroup -g 1001 appgroup && \
    adduser -D -u 1001 -G appgroup appuser && \
    chown -R appuser:appgroup /app

# Switch to non-root user
USER appuser

CMD ["node", "server.js"]
```

```dockerfile
# ❌ Bad - Running as root
FROM node:18-alpine
WORKDIR /app
COPY . .
RUN npm install
CMD ["node", "server.js"]  # Runs as root!
```

#### Don't Hardcode Secrets

```dockerfile
# ❌ Bad - Hardcoded secrets
ENV DATABASE_PASSWORD=secret123
ENV API_KEY=abc123xyz

# ✅ Good - Use runtime environment variables
ENV DATABASE_PASSWORD=${DATABASE_PASSWORD}
```

```yaml
# docker-compose.yml
services:
  backend:
    environment:
      - DATABASE_PASSWORD=${DATABASE_PASSWORD}
    env_file:
      - .env.local
```

```bash
# .env.local (add to .gitignore!)
DATABASE_PASSWORD=secret123
API_KEY=abc123xyz
```

#### Scan Images for Vulnerabilities

```bash
# Scan image with Docker Scout
docker scout cves my-image:latest

# Scan with Trivy
docker run --rm -v /var/run/docker.sock:/var/run/docker.sock \
  aquasec/trivy image my-image:latest
```

### 2. Performance Best Practices

#### Use Multi-Stage Builds

```dockerfile
# ✅ Good - Multi-stage build
FROM node:18-alpine AS builder
WORKDIR /app
COPY package*.json ./
RUN npm ci
COPY . .
RUN npm run build

FROM node:18-alpine
WORKDIR /app
COPY --from=builder /app/dist ./dist
COPY --from=builder /app/node_modules ./node_modules
USER node
CMD ["node", "dist/main.js"]

# Result: ~200MB instead of ~1.2GB
```

#### Optimize Layer Caching

```dockerfile
# ✅ Good - Leverage cache
FROM node:18-alpine

WORKDIR /app

# Copy package files first (changes less frequently)
COPY package*.json ./
RUN npm ci

# Copy source code last (changes more frequently)
COPY . .

CMD ["npm", "start"]
```

```dockerfile
# ❌ Bad - Cache invalidated on every change
FROM node:18-alpine
WORKDIR /app
COPY . .              # Everything copied at once
RUN npm install
CMD ["npm", "start"]
```

#### Minimize Image Size

```dockerfile
# Use alpine variants
FROM node:18-alpine     # ~175MB
# Instead of
FROM node:18           # ~900MB

# Combine RUN commands
RUN apt-get update && \
    apt-get install -y curl vim && \
    rm -rf /var/lib/apt/lists/*

# Use .dockerignore
# node_modules
# .git
# *.md
# .env
```

### 3. Development Best Practices

#### Use .dockerignore

```.dockerignore
# Dependencies
node_modules
npm-debug.log
yarn-error.log

# Build outputs
dist
build
.next
out

# Git
.git
.gitignore

# IDE
.vscode
.idea
*.swp
*.swo

# Environment
.env
.env.local
.env.*.local

# Testing
coverage
.nyc_output

# Documentation
*.md
docs/

# Docker
Dockerfile
docker-compose*.yml
.dockerignore

# OS
.DS_Store
Thumbs.db

# Logs
logs
*.log
```

#### Use Environment-Specific Compose Files

```bash
# Development
docker-compose.yml              # Base configuration
docker-compose.override.yml     # Development overrides (auto-loaded)

# Production
docker-compose.yml              # Base configuration
docker-compose.prod.yml         # Production overrides
```

```yaml
# docker-compose.yml (base)
version: '3.8'
services:
  app:
    build: .
    environment:
      - NODE_ENV=${NODE_ENV}
```

```yaml
# docker-compose.override.yml (development - auto-loaded)
version: '3.8'
services:
  app:
    volumes:
      - .:/app
      - /app/node_modules
    command: npm run dev
```

```yaml
# docker-compose.prod.yml (production)
version: '3.8'
services:
  app:
    command: npm start
    restart: always
```

```bash
# Run development
docker-compose up

# Run production
docker-compose -f docker-compose.yml -f docker-compose.prod.yml up
```

#### Add Health Checks

```dockerfile
# Dockerfile
HEALTHCHECK --interval=30s --timeout=3s --start-period=5s --retries=3 \
  CMD node healthcheck.js || exit 1
```

```javascript
// healthcheck.js
const http = require('http');

const options = {
  host: 'localhost',
  port: 3000,
  path: '/health',
  timeout: 2000
};

const request = http.request(options, (res) => {
  console.log(`STATUS: ${res.statusCode}`);
  process.exit(res.statusCode === 200 ? 0 : 1);
});

request.on('error', (err) => {
  console.log('ERROR:', err);
  process.exit(1);
});

request.end();
```

```yaml
# docker-compose.yml
services:
  backend:
    healthcheck:
      test: ["CMD", "node", "healthcheck.js"]
      interval: 30s
      timeout: 3s
      retries: 3
      start_period: 40s
```

### 4. Naming Conventions

```yaml
# ✅ Good naming
services:
  frontend-web:
    container_name: myapp-frontend
    image: myapp/frontend:1.0.0
    
  backend-api:
    container_name: myapp-backend
    image: myapp/backend:1.0.0
    
volumes:
  postgres-data:
  redis-cache:
  
networks:
  frontend-network:
  backend-network:
```

### 5. Logging Best Practices

```dockerfile
# ✅ Log to stdout/stderr (Docker captures)
CMD ["node", "server.js"]

# ❌ Don't log to files inside container
# (Data is lost when container stops)
```

```yaml
# docker-compose.yml
services:
  app:
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"
```

```bash
# View logs
docker-compose logs -f
docker-compose logs --tail=100 backend

# Export logs
docker-compose logs > app-logs.txt
```

---

## Common Issues and Troubleshooting

### Issue 1: Port Already in Use

**Error:**
```
Error: bind: address already in use
```

**Solutions:**

```bash
# Find process using port
lsof -i :3000
netstat -ano | findstr :3000  # Windows

# Kill process
kill -9 <PID>

# Or change port in docker-compose.yml
ports:
  - "3001:3000"  # Use different host port
```

### Issue 2: Permission Denied

**Error:**
```
Permission denied while trying to connect to Docker daemon
```

**Solutions:**

```bash
# Linux - Add user to docker group
sudo usermod -aG docker $USER
newgrp docker

# Or run with sudo
sudo docker ps

# Fix Docker socket permissions
sudo chmod 666 /var/run/docker.sock
```

### Issue 3: Container Exits Immediately

**Debugging:**

```bash
# View logs
docker logs container-name

# Run in interactive mode
docker run -it my-image sh

# Override entrypoint
docker run -it --entrypoint sh my-image

# Check exit code
docker ps -a  # Look at STATUS column
```

**Common Causes:**

```dockerfile
# ❌ Bad - No long-running process
CMD ["echo", "Hello"]

# ✅ Good - Long-running process
CMD ["node", "server.js"]
CMD ["nginx", "-g", "daemon off;"]
```

### Issue 4: Cannot Connect to Database

**Debugging:**

```bash
# Check network
docker network ls
docker network inspect network-name

# Test connection from backend container
docker exec backend-container ping database-container

# Check if database is ready
docker exec database-container pg_isready -U postgres

# View database logs
docker logs database-container
```

**Solution - Use Health Checks:**

```yaml
services:
  backend:
    depends_on:
      database:
        condition: service_healthy
  
  database:
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U postgres"]
      interval: 10s
      timeout: 5s
      retries: 5
```

### Issue 5: Hot Reload Not Working

**Solutions:**

```yaml
# Enable polling for file watching
services:
  frontend:
    environment:
      - CHOKIDAR_USEPOLLING=true
      - WATCHPACK_POLLING=true
    volumes:
      - .:/app
      - /app/node_modules
```

```json
// package.json - Angular
{
  "scripts": {
    "start": "ng serve --host 0.0.0.0 --poll 2000"
  }
}
```

### Issue 6: Out of Disk Space

**Diagnosis:**

```bash
# Check disk usage
docker system df

# Detailed view
docker system df -v
```

**Solutions:**

```bash
# Remove unused containers
docker container prune

# Remove unused images
docker image prune -a

# Remove unused volumes
docker volume prune

# Clean everything
docker system prune -a --volumes

# Be specific about what to keep
docker system prune -a --filter "until=24h"
```

### Issue 7: Slow Build Times

**Solutions:**

```dockerfile
# 1. Optimize layer caching
COPY package*.json ./
RUN npm ci
COPY . .

# 2. Use .dockerignore
node_modules
.git

# 3. Use BuildKit
# Add to ~/.docker/daemon.json
{
  "features": {
    "buildkit": true
  }
}
```

```bash
# Build with BuildKit
DOCKER_BUILDKIT=1 docker build -t my-app .

# Parallel builds with docker-compose
docker-compose build --parallel
```

### Issue 8: Memory Issues

**Error:**
```
Container killed: OOM (Out of Memory)
```

**Solutions:**

```yaml
# Set memory limits
services:
  app:
    deploy:
      resources:
        limits:
          memory: 512M
        reservations:
          memory: 256M
```

```bash
# View container resource usage
docker stats

# Increase Docker memory (Docker Desktop)
# Settings → Resources → Memory
```

### Issue 9: Network Issues

**Debugging:**

```bash
# List networks
docker network ls

# Inspect network
docker network inspect network-name

# Test connectivity
docker exec container1 ping container2
docker exec container1 curl http://container2:3000

# DNS resolution
docker exec container1 nslookup container2
```

**Solutions:**

```yaml
# Use custom networks (enable DNS)
services:
  app1:
    networks:
      - app-network
  app2:
    networks:
      - app-network

networks:
  app-network:
    driver: bridge
```

### Issue 10: Environment Variables Not Working

**Debugging:**

```bash
# Check environment variables in container
docker exec container-name env

# Check docker-compose interpolation
docker-compose config
```

**Solutions:**

```yaml
# ✅ Good - Proper env var syntax
services:
  app:
    environment:
      - DATABASE_URL=${DATABASE_URL}
    env_file:
      - .env
```

```bash
# Verify .env file is in same directory
ls -la .env

# Check .env format (no quotes needed)
DATABASE_URL=postgresql://localhost:5432/mydb
```

---

## Docker Interview Questions

### Basic Level

#### 1. What is Docker and why is it useful?

**Answer:**
Docker is a containerization platform that packages applications and their dependencies into isolated containers. Benefits:
- **Consistency**: "Works on my machine" → Works everywhere
- **Isolation**: Each app runs independently
- **Portability**: Run anywhere (laptop, server, cloud)
- **Efficiency**: Lightweight compared to VMs
- **Scalability**: Easy to scale horizontally

#### 2. What's the difference between an image and a container?

**Answer:**
- **Image**: Read-only blueprint/template (recipe)
- **Container**: Running instance of an image (the meal)

```bash
# Image is template
docker pull nginx

# Container is running instance
docker run nginx  # Creates container from image

# Multiple containers from one image
docker run --name web1 nginx
docker run --name web2 nginx
```

#### 3. What is a Dockerfile?

**Answer:**
A text file with instructions to build a Docker image.

```dockerfile
FROM node:18-alpine    # Base image
WORKDIR /app          # Working directory
COPY package*.json ./ # Copy files
RUN npm install       # Execute commands
COPY . .             # Copy app code
CMD ["npm", "start"]  # Start command
```

#### 4. What's the difference between CMD and ENTRYPOINT?

**Answer:**

```dockerfile
# CMD - Can be overridden easily
CMD ["npm", "start"]
# docker run my-app npm test  ← Overrides CMD

# ENTRYPOINT - Main executable
ENTRYPOINT ["npm"]
CMD ["start"]
# docker run my-app test  ← Runs "npm test"
```

**Use Cases:**
- `CMD`: Default command that might change
- `ENTRYPOINT`: Fixed executable
- Both: Flexibility with defaults

#### 5. What is Docker Compose?

**Answer:**
Tool for defining and running multi-container applications using a YAML file.

```yaml
# docker-compose.yml
services:
  frontend:
    build: ./frontend
    ports:
      - "4200:4200"
  
  backend:
    build: ./backend
    ports:
      - "3000:3000"
    depends_on:
      - database
  
  database:
    image: postgres:15
```

```bash
# Start all services
docker-compose up

# Instead of manually running each container
```

### Intermediate Level

#### 6. Explain Docker volumes and why they're needed?

**Answer:**
Volumes persist data outside containers (containers are ephemeral).

**Types:**

```yaml
services:
  app:
    volumes:
      # Named volume (managed by Docker)
      - postgres-data:/var/lib/postgresql/data
      
      # Bind mount (host directory)
      - ./code:/app
      
      # Anonymous volume
      - /app/node_modules

volumes:
  postgres-data:
```

**Use Cases:**
- Databases: Persist data across restarts
- Development: Live code reloading
- Logs: Access logs on host

#### 7. What are Docker networks?

**Answer:**
Networks enable container communication.

```yaml
services:
  frontend:
    networks:
      - public
  
  backend:
    networks:
      - public
      - private
  
  database:
    networks:
      - private  # Not accessible from frontend

networks:
  public:
  private:
```

**Network Types:**
- `bridge`: Default, isolated network
- `host`: Use host's network
- `none`: No networking

#### 8. What is a multi-stage build?

**Answer:**
Use multiple FROM statements to create smaller images.

```dockerfile
# Build stage (large)
FROM node:18 AS builder
WORKDIR /app
COPY . .
RUN npm install && npm run build

# Production stage (small)
FROM node:18-alpine
COPY --from=builder /app/dist ./dist
CMD ["node", "dist/main.js"]

# Final image only has production artifacts
```

**Benefits:**
- Smaller images
- Faster deployments
- Separate build and runtime dependencies

#### 9. How do you debug a failing container?

**Answer:**

```bash
# 1. Check logs
docker logs container-name
docker logs -f container-name  # Follow

# 2. Inspect container
docker inspect container-name

# 3. Run interactively
docker run -it my-image sh

# 4. Execute shell in running container
docker exec -it container-name bash

# 5. Check exit code
docker ps -a  # Look at STATUS

# 6. Override entrypoint
docker run -it --entrypoint sh my-image

# 7. Check resource usage
docker stats
```

#### 10. What is .dockerignore and why use it?

**Answer:**
Excludes files from Docker build context.

```.dockerignore
node_modules
.git
*.md
.env
dist
```

**Benefits:**
- Faster builds (smaller context)
- Smaller images
- Avoid copying sensitive files
- Better caching

### Advanced Level

#### 11. How do you optimize Docker images?

**Answer:**

```dockerfile
# 1. Use alpine images
FROM node:18-alpine  # vs node:18

# 2. Multi-stage builds
FROM node:18 AS builder
...
FROM node:18-alpine
COPY --from=builder ...

# 3. Combine RUN commands (fewer layers)
RUN apt-get update && \
    apt-get install -y curl vim && \
    rm -rf /var/lib/apt/lists/*

# 4. Order by change frequency
COPY package*.json ./  # Changes less
RUN npm ci
COPY . .              # Changes more

# 5. Use .dockerignore
# 6. Don't install dev dependencies
RUN npm ci --only=production

# 7. Remove cache in same layer
RUN apt-get update && \
    apt-get install -y curl && \
    rm -rf /var/lib/apt/lists/*
```

#### 12. Explain Docker security best practices?

**Answer:**

```dockerfile
# 1. Don't run as root
RUN adduser -D appuser
USER appuser

# 2. Use specific image versions
FROM node:18.17.0-alpine  # Not :latest

# 3. Scan images
# docker scout cves my-image

# 4. Don't hardcode secrets
ENV DATABASE_PASSWORD=${DATABASE_PASSWORD}

# 5. Use read-only filesystem
docker run --read-only my-app

# 6. Limit resources
docker run --memory=512m --cpus=0.5 my-app

# 7. Drop unnecessary capabilities
docker run --cap-drop=ALL --cap-add=NET_BIND_SERVICE my-app
```

#### 13. How do you handle secrets in Docker?

**Answer:**

```yaml
# ❌ Bad - Hardcoded
ENV DATABASE_PASSWORD=secret123

# ✅ Good - Runtime environment
docker run -e DATABASE_PASSWORD=${DB_PASS} my-app

# ✅ Good - .env file (not committed)
docker-compose up  # Reads .env automatically

# ✅ Good - Docker secrets (Swarm)
docker secret create db_password ./password.txt
docker service create --secret db_password my-service

# ✅ Good - Build-time secrets (BuildKit)
RUN --mount=type=secret,id=npm_token \
    npm config set //registry.npmjs.org/:_authToken=$(cat /run/secrets/npm_token)
```

#### 14. What are Docker health checks?

**Answer:**

```dockerfile
# In Dockerfile
HEALTHCHECK --interval=30s --timeout=3s --start-period=5s --retries=3 \
  CMD curl -f http://localhost:3000/health || exit 1
```

```yaml
# In docker-compose.yml
services:
  backend:
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:3000/health"]
      interval: 30s
      timeout: 3s
      retries: 3
      start_period: 40s
    
  database:
    depends_on:
      backend:
        condition: service_healthy  # Wait for healthy
```

**Benefits:**
- Container orchestration knows when service is ready
- Automatic restarts on failure
- Load balancers can route correctly

#### 15. Difference between COPY and ADD?

**Answer:**

```dockerfile
# COPY - Simple file copy (preferred)
COPY package.json ./
COPY src/ ./src/

# ADD - Additional features:
# 1. Auto-extracts tar files
ADD archive.tar.gz /app/

# 2. Can download from URLs
ADD https://example.com/file.txt /app/

# Best Practice: Use COPY unless you need ADD's features
```

### Scenario-Based Questions

#### 16. How would you set up a development environment with Docker for a full-stack app?

**Answer:**

```yaml
version: '3.8'

services:
  # Frontend with hot reload
  frontend:
    build:
      context: ./frontend
      dockerfile: Dockerfile.dev
    ports:
      - "4200:4200"
    volumes:
      - ./frontend:/app
      - /app/node_modules
    environment:
      - CHOKIDAR_USEPOLLING=true

  # Backend with debugging
  backend:
    build:
      context: ./backend
      dockerfile: Dockerfile.dev
    ports:
      - "3000:3000"
      - "9229:9229"  # Debug port
    volumes:
      - ./backend:/app
      - /app/node_modules
    command: nodemon --inspect=0.0.0.0:9229 server.js
    depends_on:
      database:
        condition: service_healthy

  # Database with persistent data
  database:
    image: postgres:15-alpine
    environment:
      - POSTGRES_PASSWORD=dev
    volumes:
      - postgres-data:/var/lib/postgresql/data
    healthcheck:
      test: ["CMD-SHELL", "pg_isready"]
      interval: 10s

volumes:
  postgres-data:
```

```bash
# Start everything
docker-compose up

# View logs
docker-compose logs -f backend

# Execute commands
docker-compose exec backend npm test
```

#### 17. Container keeps crashing. How do you debug?

**Answer:**

```bash
# 1. Check logs
docker logs container-name
docker logs --tail=100 -f container-name

# 2. Check exit code
docker ps -a
# STATUS: Exited (0) = normal exit
# STATUS: Exited (1) = error
# STATUS: Exited (137) = killed (OOM)

# 3. Run interactively
docker run -it my-image sh

# 4. Check resource constraints
docker stats

# 5. Override entrypoint
docker run -it --entrypoint sh my-image

# 6. Check dependencies
docker-compose logs database  # Check dependencies

# 7. Inspect container config
docker inspect container-name

# 8. Test health check
docker inspect container-name | grep -A 20 Health
```

#### 18. How would you migrate data between Docker volumes?

**Answer:**

```bash
# Method 1: Using temporary container
docker run --rm \
  -v old-volume:/from \
  -v new-volume:/to \
  alpine \
  sh -c "cd /from && cp -av . /to"

# Method 2: Backup and restore
# Backup
docker run --rm \
  -v old-volume:/data \
  -v $(pwd):/backup \
  alpine \
  tar czf /backup/volume-backup.tar.gz -C /data .

# Restore
docker run --rm \
  -v new-volume:/data \
  -v $(pwd):/backup \
  alpine \
  tar xzf /backup/volume-backup.tar.gz -C /data

# Method 3: Using docker-compose
docker-compose down
docker volume create new-volume
# Update docker-compose.yml to use new-volume
docker-compose up
```

#### 19. Explain how you'd implement blue-green deployment with Docker?

**Answer:**

```yaml
# docker-compose.blue.yml
services:
  web-blue:
    image: my-app:v1
    container_name: web-blue
    networks:
      - app-network

  nginx:
    image: nginx
    ports:
      - "80:80"
    volumes:
      - ./nginx-blue.conf:/etc/nginx/nginx.conf
    networks:
      - app-network

networks:
  app-network:
```

```yaml
# docker-compose.green.yml
services:
  web-green:
    image: my-app:v2
    container_name: web-green
    networks:
      - app-network
```

```bash
# 1. Blue is running
docker-compose -f docker-compose.blue.yml up -d

# 2. Deploy green (new version)
docker-compose -f docker-compose.green.yml up -d

# 3. Test green
curl http://localhost:8080

# 4. Switch nginx to green
cp nginx-green.conf nginx.conf
docker exec nginx nginx -s reload

# 5. Remove blue
docker-compose -f docker-compose.blue.yml down
```

#### 20. How do you handle logs in production Docker containers?

**Answer:**

```yaml
# docker-compose.yml
services:
  app:
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"
        labels: "app,environment"

  # Or use centralized logging
  app-with-fluentd:
    logging:
      driver: "fluentd"
      options:
        fluentd-address: localhost:24224
        tag: docker.{{.Name}}
```

```bash
# View logs
docker-compose logs -f --tail=100

# Export logs
docker-compose logs > app.log

# Use log management tools
# - ELK Stack (Elasticsearch, Logstash, Kibana)
# - Splunk
# - Datadog
# - CloudWatch (AWS)
```

---

## Quick Reference Card

### Essential Commands

```bash
# Images
docker pull <image>           # Download image
docker build -t <name> .     # Build image
docker images                # List images
docker rmi <image>           # Remove image

# Containers
docker run <image>           # Create and start
docker run -d <image>        # Detached mode
docker run -p 8080:80        # Port mapping
docker ps                    # List running
docker ps -a                 # List all
docker stop <container>      # Stop container
docker start <container>     # Start container
docker rm <container>        # Remove container
docker exec -it <c> bash     # Execute command
docker logs <container>      # View logs

# Docker Compose
docker-compose up            # Start services
docker-compose up -d         # Detached mode
docker-compose down          # Stop services
docker-compose logs -f       # Follow logs
docker-compose ps            # List services
docker-compose exec          # Execute command

# System
docker system df             # Disk usage
docker system prune          # Clean up
docker network ls            # List networks
docker volume ls             # List volumes
```

### Dockerfile Template

```dockerfile
# Choose base image
FROM node:18-alpine

# Set working directory
WORKDIR /app

# Copy dependencies
COPY package*.json ./

# Install dependencies
RUN npm ci --only=production

# Copy application
COPY . .

# Create user
RUN adduser -D appuser
USER appuser

# Expose port
EXPOSE 3000

# Health check
HEALTHCHECK CMD curl -f http://localhost:3000/health || exit 1

# Start application
CMD ["node", "server.js"]
```

### docker-compose.yml Template

```yaml
version: '3.8'

services:
  app:
    build: .
    container_name: my-app
    ports:
      - "3000:3000"
    volumes:
      - .:/app
      - /app/node_modules
    environment:
      - NODE_ENV=development
    depends_on:
      database:
        condition: service_healthy
    networks:
      - app-network

  database:
    image: postgres:15-alpine
    environment:
      - POSTGRES_PASSWORD=${DB_PASSWORD}
    volumes:
      - db-data:/var/lib/postgresql/data
    networks:
      - app-network
    healthcheck:
      test: ["CMD-SHELL", "pg_isready"]
      interval: 10s

volumes:
  db-data:

networks:
  app-network:
```

---

## Additional Resources

### Official Documentation
- [Docker Official Docs](https://docs.docker.com/)
- [Docker Hub](https://hub.docker.com/)
- [Docker Compose Docs](https://docs.docker.com/compose/)
- [Dockerfile Reference](https://docs.docker.com/engine/reference/builder/)

### Learning Resources
- [Play with Docker](https://labs.play-with-docker.com/) - Free online Docker playground
- [Docker Curriculum](https://docker-curriculum.com/) - Comprehensive tutorial
- [Docker for Beginners](https://docker-curriculum.com/#docker-for-beginners) - Step-by-step guide

### Tools
- **Docker Desktop**: GUI for Docker (Mac/Windows)
- **Portainer**: Web-based Docker management
- **Lazydocker**: Terminal UI for Docker
- **Dive**: Inspect image layers
- **Docker Scout**: Security scanning
- **Trivy**: Vulnerability scanner

### Best Practices
- Keep images small (use alpine)
- One process per container
- Don't run as root
- Use multi-stage builds
- Leverage build cache
- Use .dockerignore
- Version everything
- Health checks in production
- Use volumes for data
- Custom networks for apps

---

## Conclusion

Docker has become an essential skill for modern developers. This guide covered:

✅ Core Docker concepts (images, containers, volumes, networks)
✅ Dockerfile creation and best practices
✅ Docker Compose for multi-container apps
✅ Frontend development (Angular, React, Vue)
✅ Backend development (Node.js, NestJS, Flask)
✅ Security and performance optimization
✅ Troubleshooting common issues
✅ Interview questions and answers

### Next Steps

1. **Practice**: Set up your first Dockerized project
2. **Experiment**: Try different configurations
3. **Build**: Create multi-container applications
4. **Deploy**: Use Docker in CI/CD pipelines
5. **Learn More**: Explore Kubernetes for orchestration

### Remember

- Start simple, then optimize
- Read error messages carefully
- Use official images when possible
- Keep security in mind
- Document your configurations
- Version control everything

Happy Dockerizing! 🐋

---

*Last Updated: October 2025*
*Author: Created for Junior Frontend & Backend Developers*

